{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planteamiento del problema\n",
    "\n",
    "La enfermedad de Alzheimer es un trastorno neurodegenerativo y la forma más común de demencia. La predicción precisa y el diagnóstico de la enfermedad de Alzheimer (EA) y su etapa prodromal, como el deterioro cognitivo leve, son esenciales para la detección temprana. Uno de los métodos clave para diagnosticar esta enfermedad y monitorear su progresión es a través de la resonancia magnética (RM), que proporciona información detallada sobre la estructura y función del cerebro.\n",
    "\n",
    "El objetivo principal de esta investigación es desarrollar y evaluar un modelo de **Deep Learning** capaz de identificar patrones distintivos en imágenes de RM que permitan discriminar entre diferentes etapas de pacientes con Alzheimer. Esto podría tener un impacto significativo en la detección temprana de la enfermedad, facilitando así intervenciones más efectivas y mejorando la calidad de vida de los pacientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contenido\n",
    "\n",
    "Los datos consisten en imágenes de resonancia magnética (RM). Los datos tienen cuatro clases de imágenes tanto en el conjunto de entrenamiento como en el de pruebas:\n",
    "\n",
    "- Demencia leve\n",
    "- Demencia moderada\n",
    "- No demente\n",
    "- Demencia muy leve\n",
    "\n",
    "Los conjuntos de datos se extraen del Proyecto de Series de Estudios de Imágenes de Acceso Abierto (OASIS, por sus siglas en inglés) (https://www.oasis-brains.org), que es un proyecto destinado a poner conjuntos de datos de neuroimagen del cerebro libremente disponibles para la comunidad científica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodología\n",
    "\n",
    "Se han seguido los siguientes pasos para preparar las imágenes para el análisis. Se ha desarrollado un modelo convolucional desde cero que se comparó con algunos modelos en los que se ha utilizado Transfer Learning. Para ello, se ha desarrollado un conjunto de funciones auxiliares para agilizar tareas para su uso repetido durante el análisis.\n",
    "\n",
    "+ **1. Preparación de datos**\n",
    "    + Importar bibliotecas\n",
    "    + Construcción de funciones auxiliares\n",
    "    + Preprocesamiento de imágenes para el análisis\n",
    "    + Visualización de imágenes de muestra\n",
    "    + Visualización de la proporción de clases\n",
    "+ **2. Comparación de modelos**\n",
    "    + Modelo base: Random Forest\n",
    "    + Modelo convolucional simple (modelo CNN)\n",
    "    + Transfer Learning:\n",
    "        - ResNet50\n",
    "        - InceptionV3\n",
    "        - DenseNet169\n",
    "        - VGG16\n",
    "    + Resumen y conclusiones, seleccionar el mejor modelo para ajustar\n",
    "+ **3. Ajuste del modelo**\n",
    "    + Fine tuning\n",
    "    + Aumento de datos (Data augmentation)\n",
    "+ **4. Evaluación del rendimiento en imágenes de prueba**\n",
    "+ **5. Conclusiones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, vamos a importar todas las bibliotecas necesarias para realizar el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "# System libraries\n",
    "import os\n",
    "import os.path\n",
    "from   os import path\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from distutils.dir_util import copy_tree, remove_tree\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "\n",
    "# Images, Plotting\n",
    "from skimage import io\n",
    "import tensorflow.keras.preprocessing\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend, models, layers, Sequential\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Add\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import DenseNet121,InceptionV3, Xception, ResNet101, VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import load_model\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "# Turn off warnings for cleaner looking notebook\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrucción de funciones auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta funciones nos ayudarán a agilizar tareas para su uso repetido durante el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función es esencialmente un cargador de datos para tareas de clasificación de imágenes.\n",
    "# Lee imágenes de un directorio, las redimensiona a una dimensión especificada y las recopila junto con sus etiquetas correspondientes.\n",
    "\n",
    "def read_data(directory, reshape_dim=(176, 176)):\n",
    "    X = []\n",
    "    y = []\n",
    "    for folder in os.listdir(directory):\n",
    "        if os.path.isdir(os.path.join(directory, folder)):\n",
    "            label = folder\n",
    "            for file in os.listdir(os.path.join(directory, folder)):\n",
    "                image_path = os.path.join(directory, folder, file)\n",
    "                if os.path.isfile(image_path):\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.resize(image, reshape_dim)\n",
    "                    X.append(image)\n",
    "                    y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función es para visualizar un conjunto de imágenes aleatorias con sus etiquetas \n",
    "# correspondientes para realizar una inspección rápida del conjunto de datos.\n",
    "\n",
    "def show_random_images_with_labels(X, y, num_images=10, rows=2, cols=5):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 6))\n",
    "    indices = np.random.choice(len(X), num_images, replace=False)\n",
    "    for idx, ax in zip(indices, axes.ravel()):\n",
    "        image = X[idx]\n",
    "        label = y[idx]\n",
    "        ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        ax.set_title(f\"Label: {label}\")\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función es para preparar datos de imagen para modelos de aprendizaje automático que \n",
    "# requieren vectores de características aplanados como entrada. \n",
    "# Además, proporciona la opción de convertir imágenes a escala de grises, lo cual puede ser \n",
    "# beneficioso para reducir la complejidad computacional.\n",
    "\n",
    "def flatten_gray_scale(array_in, gray=True):\n",
    "    def convert_to_gray_scale(color_image):\n",
    "        coefficients = np.array([0.2989, 0.5870, 0.1140])\n",
    "        gray_image = np.dot(color_image[..., :3], coefficients)\n",
    "        return gray_image\n",
    "\n",
    "    if array_in.shape[-1] == 3 and gray:\n",
    "        array_in = np.array([convert_to_gray_scale(image) for image in array_in])\n",
    "    return array_in.reshape(array_in.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función analiza el rendimiento de un modelo durante las fases de entrenamiento y validación, \n",
    "# así como proporciona información sobre su rendimiento en datos de prueba no vistos a través de métricas y visualizaciones. \n",
    "# Además, proporciona una matriz de confusión para comprender las predicciones por clase.\n",
    "\n",
    "def plot_training_metrics(train_hist, model, test_gen_plot, y_actual, y_pred, classes, model_name):\n",
    "    \"\"\"\n",
    "    Entrada: historial del modelo entrenado, modelo, generador de imágenes de prueba, etiquetas reales y predichas, lista de clases\n",
    "    Salida: Gráficos de pérdida vs épocas, precisión vs épocas, matriz de confusión\n",
    "    \"\"\"\n",
    "    \n",
    "    # Evaluar los resultados:\n",
    "    test_metrics = model.evaluate(test_gen_plot, verbose=False)\n",
    "    AUC = test_metrics[1] * 100\n",
    "    Acc = test_metrics[2] * 100 \n",
    "    resultados_título = f\"\\n Modelo AUC {AUC:.2f}%, Precisión {Acc:.2f}% en Datos de Prueba\\n\"\n",
    "    print(resultados_título.format(AUC, Acc))\n",
    "\n",
    "    # imprimir informe de clasificación\n",
    "    print(classification_report(y_actual, y_pred, target_names=classes))\n",
    "\n",
    "    # extraer datos del historial de entrenamiento para trazar\n",
    "    history_dict = train_hist.history\n",
    "    valores_pérdida = history_dict['loss']\n",
    "    val_valores_pérdida = history_dict['val_loss']\n",
    "    valores_auc = history_dict['auc']\n",
    "    val_valores_auc = history_dict['val_auc']\n",
    "    épocas = range(1, len(history_dict['auc']) + 1)\n",
    "\n",
    "    # obtener la pérdida mínima y la máxima precisión para trazar\n",
    "    máx_auc = np.max(val_valores_auc)\n",
    "    mín_pérdida = np.min(val_valores_pérdida)\n",
    "    \n",
    "    # Establecer el fondo a gris\n",
    "    plt.style.use('ggplot')\n",
    "    \n",
    "    # crear gráficos\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    # trazar pérdida por épocas\n",
    "    axs[0].plot(épocas, valores_pérdida, 'bo', label='Pérdida de entrenamiento')\n",
    "    axs[0].plot(épocas, val_valores_pérdida, 'cornflowerblue', label='Pérdida de validación')\n",
    "    axs[0].set_title('Pérdida de Validación por Épocas')\n",
    "    axs[0].set_xlabel('Épocas')\n",
    "    axs[0].set_ylabel('Pérdida')\n",
    "    axs[0].axhline(y=mín_pérdida, color='darkslategray', linestyle='--')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # trazar precisión por épocas\n",
    "    axs[1].plot(épocas, valores_auc, 'bo', label='AUC de entrenamiento')\n",
    "    axs[1].plot(épocas, val_valores_auc, 'cornflowerblue', label='AUC de validación')\n",
    "    axs[1].plot(épocas, [AUC / 100] * len(épocas), 'darkmagenta', linestyle='--', label='AUC de prueba')\n",
    "    axs[1].set_title('AUC de Validación por Épocas')\n",
    "    axs[1].set_xlabel('Épocas')\n",
    "    axs[1].set_ylabel('AUC')\n",
    "    axs[1].axhline(y=máx_auc, color='darkslategray', linestyle='--')\n",
    "    axs[1].legend()\n",
    "\n",
    "    # calcular Matriz de Confusión\n",
    "    cm = confusion_matrix(y_actual, y_pred)\n",
    "\n",
    "    # crear gráfico de matriz de confusión\n",
    "    im = axs[2].imshow(cm, interpolation='nearest', cmap=plt.cm.BuPu)\n",
    "    axs[2].set_title(f\"Matriz de Confusión \\nAUC: {AUC:.2f}%\")\n",
    "    axs[2].set_xticks(np.arange(len(classes)))\n",
    "    axs[2].set_yticks(np.arange(len(classes)))\n",
    "    axs[2].set_xticklabels(classes, rotation=45)\n",
    "    axs[2].set_yticklabels(classes)\n",
    "\n",
    "    # recorrer la matriz, trazar cada elemento\n",
    "    umbral = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        axs[2].text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > umbral else \"black\")\n",
    "\n",
    "    axs[2].set_ylabel('Etiqueta real')\n",
    "    axs[2].set_xlabel('Etiqueta predicha')\n",
    "    axs[2].grid(False)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{model_name}.pdf\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función prepara los datos de prueba, obtiene predicciones del modelo y proporciona las etiquetas reales y predichas, \n",
    "# que pueden ser utilizadas para una evaluación adicional del rendimiento del modelo.\n",
    "\n",
    "def prepare_for_test(model, test_gen):\n",
    "    data, y_true = test_gen.next()\n",
    "    y_pred_ = model.predict(data, batch_size = 64)\n",
    "    y_pred = []\n",
    "    for i in range(y_pred_.shape[0]):\n",
    "        y_pred.append(np.argmax(y_pred_[i]))\n",
    "        \n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función sirve para visualizar un subconjunto de imágenes de un lote junto con sus etiquetas, \n",
    "# y opcionalmente, sus etiquetas predichas para comparación\n",
    "\n",
    "def show_images(generator,y_pred=None):\n",
    "    \"\"\"\n",
    "    Input: An image generator,predicted labels (optional)\n",
    "    Output: Displays a grid of 9 images with lables\n",
    "    \"\"\"\n",
    "    \n",
    "    # get image lables\n",
    "    labels =dict(zip([0,1,2,3], CLASSES))\n",
    "    \n",
    "    # get a batch of images\n",
    "    x,y = generator.next()\n",
    "    \n",
    "    # display a grid of 9 images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if y_pred is None:\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(x[i])\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Class:{}\".format(labels[np.argmax(y[i])]))\n",
    "                                                     \n",
    "    else:\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(x[i])\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento de imágenes para el análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mostraremos la informacion de las imagenes y las clases tanto del directorio de train como de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the images are located\n",
    "train_dir = \"./data_sample/train\"\n",
    "\n",
    "# Load images and labels\n",
    "X_train, y_train = read_data(train_dir)\n",
    "\n",
    "# Show information about the loaded images\n",
    "print(\"Number of loaded images:\", len(X_train))\n",
    "print(\"Dimensions of the image matrix:\", X_train.shape)\n",
    "print(\"Number of loaded labels:\", len(y_train))\n",
    "print(\"First 5 labels:\", y_train[:5])  # Show the first 5 labels as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the images are located\n",
    "test_dir = \"./data_sample/test\"\n",
    "\n",
    "# Load images and labels\n",
    "X_test, y_test = read_data(test_dir)\n",
    "\n",
    "# Show information about the loaded images\n",
    "print(\"Number of loaded images:\", len(X_test))\n",
    "print(\"Dimensions of the image matrix:\", X_test.shape)\n",
    "print(\"Number of loaded labels:\", len(y_test))\n",
    "print(\"First 5 labels:\", y_test[:5])  # Show the first 5 labels as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train[123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de imágenes de muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, haciendo uso de la función generada para ello, pasamos a ver algunas de las imagenes de muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_images_with_labels(X_train, y_train, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de la proporción de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo, procedemos a mirar el numero de imágenes por clase para ver si es un conjunto equilibrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.hist(y_train, bins=len(np.unique(y_train)), edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images per class in train dataset')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y',linestyle = \"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Comparación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo base: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos un modelo de Random Forest como baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero aplicamos la funcion de aplanado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf = flatten_gray_scale(X_train)\n",
    "len(X_train_rf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuócion aplicamos el shuffle (aleatoriedad):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf_shuffled, y_train_shuffled = shuffle(X_train_rf, y_train, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "np.mean(cross_val_score(rf_clf,X_train_rf_shuffled, y_train_shuffled, cv = 5, scoring = \"accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92% the accuracy debería ser lo mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo convolucional simple (CNN model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso vamos a generar y probar un modelo de red convolucional simple diseñado \"a mano\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar vamos a definir ciertos directorios asi como semillas o seeds, valores que utilizaremos repetidamente a posteriori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./data_sample/\"\n",
    "root_dir = \"./\"\n",
    "train_dir = base_dir + \"train/\"\n",
    "test_dir = base_dir + \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [ 'NonDemented',\n",
    "            'VeryMildDemented',\n",
    "            'MildDemented',\n",
    "            'ModerateDemented']\n",
    "\n",
    "IMG_SIZE = 176\n",
    "IMAGE_SIZE = [176, 176]\n",
    "DIM = (IMG_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente paso vamos a hacer uso de keras para la generación de los sets de entrenamiento, validación y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = IDG(rescale = 1./255, validation_split=0.1)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(directory=train_dir,\n",
    "                                             target_size=DIM,\n",
    "                                             batch_size=400,\n",
    "                                             class_mode='categorical',\n",
    "                                             subset='training',\n",
    "                                             shuffle=True)\n",
    "\n",
    "validation_gen = datagen.flow_from_directory(directory=train_dir,\n",
    "                                             target_size=DIM,\n",
    "                                             batch_size=400,\n",
    "                                             class_mode='categorical',\n",
    "                                             subset='validation',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_gen = datagen.flow_from_directory(directory=test_dir,\n",
    "                                             target_size=DIM,\n",
    "                                             batch_size=6400,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este de test con menos batch_size para el plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen_plot = datagen.flow_from_directory(directory=test_dir,\n",
    "                                             target_size=DIM,\n",
    "                                             batch_size=128,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, generamos y entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "# Add pooling layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another convolutional and pooling layers\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten for the dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Out layer with softmax activation for classification\n",
    "model.add(Dense(len(CLASSES), activation='softmax'))\n",
    "\n",
    "# Compile the model with personalized metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[AUC(name='auc'), Precision(name='precision'), Recall(name='recall')])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_gen,\n",
    "                    epochs=50,\n",
    "                    validation_data=validation_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos valores necesarios para generar los plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model predictions on the validation dataset.\n",
    "y_pred_prob = model.predict(validation_gen)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Get the true labels from the validation dataset.\n",
    "y_true = validation_gen.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el plot de las métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(history, model, test_gen_plot, y_true, y_pred, CLASSES, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este siguiente apartado, vamos a utilizar diferentes modelos de transfer learning, y finalmente haremos una comparativa de todos, para concluir cual podriamos mejorar para la tarea de predecir las clases de manera efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación y de manera similar al apartado anterior, generamos, entrenamos el modelo, lo evaluamos y obtenemos las métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = ResNet50(input_shape=(IMG_SIZE,IMG_SIZE,3), weights='imagenet', include_top=False)\n",
    "for layer in rn.layers:\n",
    "    layer.trainable = False\n",
    "x = Flatten()(rn.output)\n",
    "\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=rn.input, outputs=prediction)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "loss=tensorflow.losses.CategoricalCrossentropy(),\n",
    "metrics=[keras.metrics.AUC(name='auc'),'acc'])\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            patience=8,\n",
    "                                            restore_best_weights=True)\n",
    "\n",
    "tic = time.perf_counter()\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(train_gen),\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=len(validation_gen),\n",
    "                    epochs=50, callbacks=callback)\n",
    "# time\n",
    "toc = time.perf_counter()\n",
    "print(\"Total Time:{}\".format(round((toc-tic)/60,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prepare_for_test(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(history, model, test_gen_plot, y_true, y_pred, CLASSES, model_name = \"resnet50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente guardamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./alzheimer_resnet50_model\"\n",
    "model.save(model_dir, save_format='h5')\n",
    "np.save('my_resnet50_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos lo exactamente lo mismo que para el modelo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = InceptionV3(input_shape=(IMG_SIZE,IMG_SIZE,3), weights='imagenet', include_top=False)\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False\n",
    "x = Flatten()(inception.output)\n",
    "\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inception.input, outputs=prediction)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "loss=tensorflow.losses.CategoricalCrossentropy(),\n",
    "metrics=[keras.metrics.AUC(name='auc'),'acc'])\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            patience=8,\n",
    "                                            restore_best_weights=True)\n",
    "\n",
    "tic = time.perf_counter()\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(train_gen),\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=len(validation_gen),\n",
    "                    epochs=50, callbacks=callback)\n",
    "# time\n",
    "toc = time.perf_counter()\n",
    "print(\"Total Time:{}\".format(round((toc-tic)/60,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prepare_for_test(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(history, model, test_gen_plot, y_true, y_pred, CLASSES, model_name = \"inceptionv3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./alzheimer_inceptionv3_model\"\n",
    "model.save(model_dir, save_format='h5')\n",
    "np.save('my_inceptionv3_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DenseNet169"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos exactamente lo mismo que para los modelos previos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = DenseNet169(input_shape=(IMG_SIZE,IMG_SIZE,3), weights='imagenet', include_top=False)\n",
    "for layer in dense.layers:\n",
    "    layer.trainable = False\n",
    "x = Flatten()(dense.output)\n",
    "\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=dense.input, outputs=prediction)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "loss=tensorflow.losses.CategoricalCrossentropy(),\n",
    "metrics=[keras.metrics.AUC(name='auc'),'acc'])\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            patience=8,\n",
    "                                            restore_best_weights=True)\n",
    "\n",
    "tic = time.perf_counter()\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(train_gen),\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=len(validation_gen),\n",
    "                    epochs=50, callbacks=callback)\n",
    "# time\n",
    "toc = time.perf_counter()\n",
    "print(\"Total Time:{}\".format(round((toc-tic)/60,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prepare_for_test(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(history, model, test_gen_plot, y_true, y_pred, CLASSES, model_name = \"densenet169\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./alzheimer_densenet169_model\"\n",
    "model.save(model_dir, save_format='h5')\n",
    "np.save('my_densenet169_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos exactamente lo mismo que para los modelos previos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape=(IMG_SIZE,IMG_SIZE,3), weights='imagenet', include_top=False)\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "x = Flatten()(vgg.output)\n",
    "\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "loss=tensorflow.losses.CategoricalCrossentropy(),\n",
    "metrics=[keras.metrics.AUC(name='auc'),'acc'])\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)\n",
    "tic = time.perf_counter()\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(train_gen),\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=len(validation_gen),\n",
    "                    epochs=20, callbacks=callback)\n",
    "# time\n",
    "toc = time.perf_counter()\n",
    "print(\"Total Time:{}\".format(round((toc-tic)/60,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prepare_for_test(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(history, model, test_gen_plot, y_true, y_pred, CLASSES, model_name = \"vgg16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./alzheimer_vgg16_model\"\n",
    "model.save(model_dir, save_format='h5')\n",
    "np.save('my_vgg16_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumen y conclusiones, seleccionar el mejor modelo para ajustar\n",
    "\n",
    "**En resumen:**\n",
    "\n",
    "**CNN model:**\n",
    "\n",
    "- AUC: 79.03%\n",
    "- Accuracy: 58.87%\n",
    "- Precision para NonDemented: 0.13, VeryMildDemented: 0.00, MildDemented: 0.47, ModerateDemented: 0.32\n",
    "- Recall para NonDemented: 0.13, VeryMildDemented: 0.00, MildDemented: 0.46, ModerateDemented: 0.34\n",
    "- F1-score para NonDemented: 0.13, VeryMildDemented: 0.00, MildDemented: 0.47, ModerateDemented: 0.33\n",
    "\n",
    "**ResNet50:**\n",
    "\n",
    "- AUC: 83.29%\n",
    "- Accuracy: 53.95%\n",
    "- Precision para NonDemented: 0.40, VeryMildDemented: 1.00, MildDemented: 0.83, ModerateDemented: 0.43\n",
    "- Recall para NonDemented: 0.17, VeryMildDemented: 0.08, MildDemented: 0.45, ModerateDemented: 0.83\n",
    "- F1-score para NonDemented: 0.24, VeryMildDemented: 0.15, MildDemented: 0.58, ModerateDemented: 0.57\n",
    "\n",
    "**InceptionV3:**\n",
    "\n",
    "- AUC: 84.00%\n",
    "- Accuracy: 60.20%\n",
    "- Precision para NonDemented: 0.73, VeryMildDemented: 1.00, MildDemented: 0.81, ModerateDemented: 0.48\n",
    "- Recall para NonDemented: 0.20, VeryMildDemented: 0.17, MildDemented: 0.54, ModerateDemented: 0.86\n",
    "- F1-score para NonDemented: 0.31, VeryMildDemented: 0.29, MildDemented: 0.65, ModerateDemented: 0.62\n",
    "\n",
    "**DenseNet169:**\n",
    "\n",
    "- AUC: 86.79%\n",
    "- Accuracy: 62.39%\n",
    "- Precision para NonDemented: 0.92, VeryMildDemented: 1.00, MildDemented: 0.61, ModerateDemented: 0.66\n",
    "- Recall para NonDemented: 0.06, VeryMildDemented: 0.08, MildDemented: 0.95, ModerateDemented: 0.40\n",
    "- F1-score para NonDemented: 0.12, VeryMildDemented: 0.15, MildDemented: 0.74, ModerateDemented: 0.50\n",
    "\n",
    "**VGG16:**\n",
    "\n",
    "- AUC: 89.00%\n",
    "- Accuracy: 65.91%\n",
    "- Precision para NonDemented: 0.83, VeryMildDemented: 1.00, MildDemented: 0.67, ModerateDemented: 0.63\n",
    "- Recall para NonDemented: 0.11, VeryMildDemented: 0.17, MildDemented: 0.88, ModerateDemented: 0.57\n",
    "- F1-score para NonDemented: 0.20, VeryMildDemented: 0.29, MildDemented: 0.76, ModerateDemented: 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusiones hasta ahora:**\n",
    "\n",
    "Como se mencionó anteriormente, para determinar qué modelo es el mejor, dado que las clases están altamente desbalanceadas, simplemente mirar la precisión puede no ser suficiente. Necesitamos considerar varios factores, accuracy, precision, recall, F1-score, and AUC (Area Under the Curve). Basándonos en estas métricas:\n",
    "\n",
    "- **AUC and Accuracy**: VGG16 tiene el AUC más alto (89.00%) y precisión (65.91%) entre todos los modelos, lo que indica su capacidad para discriminar entre clases y su rendimiento predictivo general.\n",
    "\n",
    "- **Precision and Recall**: VGG16 también muestra valores competitivos de precisión y sensibilidad en todas las clases en comparación con otros modelos. Sin embargo, todavía tiene dificultades con la sensibilidad para la clase 'NonDemented'.\n",
    "\n",
    "- **F1-score**: VGG16 muestra puntuaciones F1 relativamente altas para la mayoría de las clases, lo que indica un buen equilibrio entre precisión y sensibilidad. Sin embargo, todavía tiene una puntuación F1 relativamente baja para la clase 'NonDemented'.\n",
    "\n",
    "Considerando el rendimiento general en todas las métricas, **VGG16** parece ser el mejor modelo entre los proporcionados, mostrando el AUC y la precisión más altos, junto con valores competitivos de precisión, sensibilidad y puntuación F1 en la mayoría de las clases. Sin embargo, como identificar con precisión la clase 'No Demenciado' es crucial, se necesita una investigación adicional o ajustes al modelo.\n",
    "\n",
    "Sin embargo, para este caso en el que seleccionar la clase precisa para diagnósticos y considerar el rendimiento general en todas las clases, **DenseNet169** parece ser la mejor opción ya que mantiene una precisión, sensibilidad y puntuación F1 relativamente altas en todas las clases. Logra un buen equilibrio entre identificar correctamente instancias de cada clase y minimizar las clasificaciones incorrectas. Por lo tanto, DenseNet169 podría ser el mejor modelo para seleccionar clases precisas para diagnósticos mientras se garantiza un rendimiento general.\n",
    "\n",
    "**Agregar optimización del modelo o agregar data augmentation puede resultar en un mejor rendimiento en el conjunto de datos de prueba.**\n",
    "\n",
    "--> **Vamos a mejorar los modelos VGG16 y DenseNet169**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ajuste del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DenseNet169**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mejorar el modelo, descongelamos las ultimas 10 capas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained DenseNet169 model\n",
    "dense = DenseNet169(input_shape=(IMG_SIZE, IMG_SIZE, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# Unfreeze the last few convolutional blocks for fine-tuning\n",
    "for layer in dense.layers[:-10]:  # Unfreeze the last 10 layers for fine-tuning\n",
    "    layer.trainable = True\n",
    "\n",
    "# Flatten the output of DenseNet169 and add a dense layer for classification\n",
    "x = Flatten()(dense.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=dense.input, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.AUC(name='auc'), 'acc'])\n",
    "\n",
    "# Define early stopping callback\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=8,\n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "# Start training\n",
    "tic = time.perf_counter()\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(train_gen),\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=len(validation_gen),\n",
    "                    epochs=50,\n",
    "                    callbacks=callback\n",
    ")\n",
    "toc = time.perf_counter()\n",
    "\n",
    "# Print total training time\n",
    "print(\"Total Time: {}\".format(round((toc-tic)/60, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prepare_for_test(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(history, model, test_gen_plot, y_true, y_pred, CLASSES, model_name = \"dense_fine_tunning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./alzheimer_dense_fine_model\"\n",
    "model.save(model_dir, save_format='h5')\n",
    "np.save('my_dense_fine_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG16**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, congelamos todas las capas excepto el ultimo bloque convolucional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained VGG16 model\n",
    "vgg = VGG16(input_shape=(IMG_SIZE, IMG_SIZE, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze all layers except the last convolutional block\n",
    "for layer in vgg.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output of VGG16 and add a dense layer for classification\n",
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.AUC(name='auc'), 'acc'])\n",
    "\n",
    "# Define early stopping callback\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=3,\n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "# Start training\n",
    "tic = time.perf_counter()\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(train_gen),\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=len(validation_gen),\n",
    "                    epochs=30, callbacks=callback)\n",
    "toc = time.perf_counter()\n",
    "\n",
    "# Print total training time\n",
    "print(\"Total Time: {}\".format(round((toc-tic)/60, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prepare_for_test(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(history, model, test_gen_plot, y_true, y_pred, CLASSES, model_name = \"vgg16_fine_tunning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./alzheimer_vgg16_fine_model\"\n",
    "model.save(model_dir, save_format='h5')\n",
    "np.save('my_vgg16_fine_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aumento de datos (Data augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, realizamos data augmentation mediante ImageDataGenerator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DenseNet169**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained DenseNet169 model\n",
    "dense = DenseNet169(input_shape=(IMG_SIZE, IMG_SIZE, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze all layers except the last convolutional block\n",
    "for layer in dense.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output of DenseNet169 and add a dense layer for classification\n",
    "x = Flatten()(dense.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=dense.input, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.AUC(name='auc'), 'acc'])\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=8,\n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "# Start training\n",
    "tic = time.perf_counter()\n",
    "history = model.fit(\n",
    "    train_datagen.flow(train_gen),\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=len(validation_gen),\n",
    "    epochs=50,\n",
    "    callbacks=callback\n",
    ")\n",
    "toc = time.perf_counter()\n",
    "\n",
    "# Print total training time\n",
    "print(\"Total Time: {}\".format(round((toc-tic)/60, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prepare_for_test(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(history, model, test_gen_plot, y_true, y_pred, CLASSES, model_name = \"dense_aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./alzheimer_dense_aug\"\n",
    "model.save(model_dir, save_format='h5')\n",
    "np.save('my_dense_aug_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG16**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model\n",
    "vgg = VGG16(input_shape=(IMG_SIZE, IMG_SIZE, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze all layers except the last convolutional block\n",
    "for layer in vgg.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten the output of VGG16 and add a dense layer for classification\n",
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.AUC(name='auc'), 'acc'])\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=3,\n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "# Start training\n",
    "tic = time.perf_counter()\n",
    "history = model.fit(\n",
    "    train_datagen.flow(train_gen),\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=len(validation_gen),\n",
    "    epochs=30,\n",
    "    callbacks=callback\n",
    ")\n",
    "toc = time.perf_counter()\n",
    "\n",
    "# Print total training time\n",
    "print(\"Total Time: {}\".format(round((toc-tic)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prepare_for_test(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(history, model, test_gen_plot, y_true, y_pred, CLASSES, model_name = \"vgg16_aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./alzheimer_vgg16_aug_model\"\n",
    "model.save(model_dir, save_format='h5')\n",
    "np.save('my_vgg16_aug_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los dos últimos modelos con los gnerados en primer lugar:\n",
    "\n",
    "- DenseNet169 Fine-tuned supera a los modelos iniciales en cuanto a AUC, precisión, recall y F1-score, mostrando una mejora significativa en todas las métricas.\n",
    "- VGG16 Fine-tuned también supera a los modelos iniciales, especialmente en términos de AUC, precisión, recall y F1-score. Sin embargo, la mejora no es tan sustancial como la de DenseNet169 Fine-tuned.\n",
    "\n",
    "Por lo tanto, en comparación con los primeros modelos proporcionados, tanto DenseNet169 Fine-tuned como VGG16 Fine-tuned muestran mejoras significativas en las métricas de rendimiento, siendo **DenseNet169 Fine-tuned** el modelo que exhibe un rendimiento superior en general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluación del rendimiento en imágenes de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, probamos a etiquetar las imágenes con el mejor modelo generado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./alzheimer_dense_fine_model\"\n",
    "history_file = 'my_dense_fine_history.npy'\n",
    "model = load_model(model_dir)\n",
    "history = np.load(history_file, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prepare_for_test(model, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por último visualizamos la predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(train_gen, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándonos en los resultados obtenidos al evaluar varios modelos de Deep Learning para la clasificación de etapas de la enfermedad de Alzheimer utilizando imágenes de resonancia magnética (MRI), se pueden obtener varias conclusiones para este proyecto:\n",
    "\n",
    "**Rendimiento del modelo:**\n",
    "\n",
    "- Se han evaluado diferentes arquitecturas de Deep Learning para la capacidad de discriminar entre las diferentes etapas de la enfermedad de Alzheimer utilizando imágenes de resonancia magnética.\n",
    "- Entre los modelos evaluados, DenseNet169 y VGG16 han demostrado el mejor rendimiento en términos de AUC y precisión, especialmente después del fine-tuning.\n",
    "- El fine-tuning de los modelos mejoró su rendimiento, lo que indica la importancia del aTransfer Learning y la mejora específica para las tareas de análisis de imágenes.\n",
    "\n",
    "**Impacto en la detección temprana de la enfermedad:**\n",
    "\n",
    "- El alto rendimiento de los modelos de Deep Learning desarrollados sugiere su utilidad potencial en la detección temprana de la enfermedad de Alzheimer.\n",
    "- La detección temprana es crucial para intervenciones y manejo oportunos de la enfermedad, lo que potencialmente conduce a mejores resultados de tratamiento y una mejor calidad de vida para los pacientes.\n",
    "\n",
    "**Implicaciones clínicas:**\n",
    "\n",
    "- Implementar un modelo de aprendizaje profundo fiable para la clasificación de etapas de la enfermedad de Alzheimer podría ayudar a los médicos a realizar diagnósticos y decisiones de tratamiento más precisos.\n",
    "- El modelo podría servir como una herramienta valiosa para radiólogos y neurólogos, ayudando en la interpretación de escáneres de MRI y proporcionando información adicional sobre la progresión de la enfermedad.\n",
    "\n",
    "**Perspectivas futuras:**\n",
    "\n",
    "- Futuras investigaciones podrían centrarse en mejorar los modelos y explorar modalidades de imágenes adicionales (por ejemplo, escáneres PET) para mejorar la precisión del diagnóstico y la clasificación de la enfermedad de Alzheimer.\n",
    "- La colaboración con profesionales e instituciones de atención médica podría facilitar la integración de los modelos desarrollados en la práctica clínica, permitiendo un impacto y validación en el mundo real.\n",
    "\n",
    "En resumen, el desarrollo y la evaluación exitosos de estos modelos para identificar patrones distintivos en imágenes de MRI de pacientes con Alzheimer representan un paso significativo hacia la mejora de la detección temprana de la enfermedad y los resultados de los pacientes en el campo de la neurología y la imagen médica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
